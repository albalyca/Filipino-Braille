import cv2
import numpy as np
import math
import os
import matplotlib.pyplot as plt
from skimage.feature import hog
from skimage.transform import resize



path = ‘insert/path/here’
image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
plt.imshow(image, cmap='gray')
plt.show()

# image processing

blurred = cv2.GaussianBlur(image, (7,7), 0)
actual_thresh = np.max(original_image)/2
threshold = math.ceil(actual_thresh)
otsu_tv, otsu_thresh = cv2.threshold(blurred, threshold, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
inverted_otsu = ~otsu_thresh

min_ones_area = 400
num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(inverted_otsu)
for label in range(1, num_labels):
    if stats[label, cv2.CC_STAT_AREA] < min_ones_area:
        inverted_otsu[labels == label] = 0

contours, _ = cv2.findContours(inverted_otsu, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
concatenated = np.concatenate(contours)
x, y, w, h = cv2.boundingRect(concatenated)
cv2.rectangle(original_image, (x, y), (x + w - 1, y + h - 1), 255, 2)
cropped = inverted_otsu[y:y+h, x:x+w]

resized = resize(cropped, (64, 128))
resized *= 255 
resized = resized.astype(np.uint8)  # convert data type to uint8
processed_image = resized
img_resized = cv2.resize(processed_image, (128, 64))

# extract HOG features

features, hog_image = hog(img_resized, orientations=9, pixels_per_cell=(8, 8),
                    cells_per_block=(2, 2), visualize=True)
features_reshaped = features.reshape(1, -1)

# predict class and output audio file

predicted_class_index = np.argmax([svc.predict(features_reshaped) for svc in svm_classifiers])
predicted_class = Classifications[predicted_class_index]
print("The predicted image is : " + predicted_class)
label = predicted_class
audio_output = gTTS(text = label, lang = 'tl', slow = False)
audio_output.save("audio_output.mp3")
os.system("start audio_output.mp3")
